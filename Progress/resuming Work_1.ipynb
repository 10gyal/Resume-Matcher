{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json('Dataset/Resume_1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1 = df['Person 2'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Distill "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akhil Yadav Polemaina\n",
      "Hyderabad, Telangana - Email me on Indeed: indeed.com/r/Akhil-Yadav-Polemaina/\n",
      "f6931801c51c63b1\n",
      "\n",
      "● Senior System Engineer at Infosys with 3.2 years of experience in software development and\n",
      "Maintenance.\n",
      "● Maintained data processing using mainframe technology for multiple front end applications of\n",
      "Walmart Retail Link platform and ensured on-time deliverables.\n",
      "● Worked on automating the uses cases to reduce manual effort in solving repeating incidents\n",
      "using Service Now orchestration.\n",
      "● Possess good analytical, logical ability and systematic approach to problem analysis, strong\n",
      "debugging and troubleshooting skills.\n",
      "● Good exposure to Retail domain.\n",
      "\n",
      "Willing to relocate to: hyderbad, Telangana\n",
      "\n",
      "WORK EXPERIENCE\n",
      "\n",
      "Senior Systems Engineer\n",
      "\n",
      "Infosys Limited -  Hyderabad, Telangana -\n",
      "\n",
      "January 2015 to Present\n",
      "\n",
      "● Working on all the Major and Minor Enhancement requests as part of Maintenance and Support\n",
      "activities\n",
      "● Identifying and fixing all the major defects in the applications, perform root cause analysis for\n",
      "production issues\n",
      "● Being a subject matter expert, involved in multiple Knowledge transfer and knowledge sharing\n",
      "sessions with the client\n",
      "● Leading a peer group and taking end to end responsibilities for all the critical issues/\n",
      "enhancements.\n",
      "● Identifying the use cases which can be automated using Service Now Orchestration\n",
      "● Creating workflows to automate various tasks which involved manual intervention\n",
      "● Direct interaction with the client on various business impacting issues on a daily basis\n",
      "● Setting up Weekly Status Review meetings and Code Review meetings with the client\n",
      "\n",
      "Senior Systems Engineer\n",
      "\n",
      "Infosys Limited -  Hyderabad, Telangana -\n",
      "\n",
      "January 2015 to Present\n",
      "\n",
      "Team Size # 5\n",
      "Project Objective:\n",
      "Providing end to end Maintenance and Support activity for data processing of the most critical and\n",
      "important Web portal 'Retail Link' along with over 40 applications used daily by all the Suppliers\n",
      "and Business users of Walmart, the largest retailer in the world. Retail link is a portal which hosts\n",
      "100's of applications developed across technologies for the suppliers which help them to carry\n",
      "on day-to-day activities right from on boarding to tracking their sales. This involves supporting\n",
      "\n",
      "https://www.indeed.com/r/Akhil-Yadav-Polemaina/f6931801c51c63b1?isid=rex-download&ikw=download-top&co=IN\n",
      "https://www.indeed.com/r/Akhil-Yadav-Polemaina/f6931801c51c63b1?isid=rex-download&ikw=download-top&co=IN\n",
      "\n",
      "\n",
      "various Decision Support System reports which helps the higher management to take business\n",
      "critical decisions.\n",
      "\n",
      "Responsibilities:\n",
      "● Working on all the Major and Minor Enhancement requests as part of Maintenance and Support\n",
      "activities\n",
      "● Identifying and fixing all the major defects in the applications, perform root cause analysis for\n",
      "production issues\n",
      "● Being a subject matter expert, involved in multiple Knowledge transfer and knowledge sharing\n",
      "sessions with the client\n",
      "● Leading a peer group and taking end to end responsibilities for all the critical issues/\n",
      "enhancements.\n",
      "● Identifying the use cases which can be automated using Service Now Orchestration\n",
      "● Creating workflows to automate various tasks which involved manual intervention\n",
      "● Direct interaction with the client on various business impacting issues on a daily basis\n",
      "● Setting up Weekly Status Review meetings and Code Review meetings with the client\n",
      "\n",
      "EDUCATION\n",
      "\n",
      "Electrical and Electronics Engineering\n",
      "\n",
      "Anurag College of Engineering (Jntuh)\n",
      "\n",
      "SKILLS\n",
      "\n",
      "servicenow (1 year), Mainframe (3 years), cobol (3 years), Jcl (3 years), Teradata (3 years)\n",
      "\n",
      "ADDITIONAL INFORMATION\n",
      "\n",
      "Technical Skills\n",
      "• Domain - Retail\n",
      "• Technology - Mainframe (COBOL, JCL, DB2, Teradata), Service now.\n",
      "• Operating System - Mainframe (z/OS)\n",
      "• Database - DB2, SQL, Teradata.\n",
      "• Utilities - FILE-AID, IDCAMS, DFSORT basics, LIBRARIAN, FTP/SFTP, CA-7 basics.\n",
      "• Tools - Query Management Tool (QMF), SQL Assistant, Service now, Remedy.\n",
      "\n",
      "Key Strengths:\n",
      "● Effective Communication Skills and Zeal to learn.\n",
      "● Flexibility and Adaptability.\n",
      "● Good Leadership Qualities.\n",
      "● Analytical and Problem Solving Skills.\n",
      "\n",
      "Achievements:\n",
      "● Received STAR award for working on various system improvement and automation activities\n",
      "● Received multiple INSTA awards for my performance in the projects worked\n"
     ]
    }
   ],
   "source": [
    "print(text_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a cleaning pipeline to clean and remove extra words as well as lemmatize the text\n",
    "\n",
    "def clean_text(text):\n",
    "    text = Distill.tokenize(text)\n",
    "    text = Distill.remove_stopwords(text)\n",
    "    text = Distill.remove_tags(text)\n",
    "    text = Distill.lemmatize(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = clean_text(text_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = Distill._to_string(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = Distill.tokenize(text_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = Distill.remove_stopwords(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = Distill.remove_tags(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = Distill.lemmatize(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \" \".join(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'indeed indeedcomrakhilyadavpolemaina year experience software development datum processing use mainframe technology multiple front end application platform ensure ontime deliverable work automate use case reduce manual effort solve repeat incident use now orchestration good analytical logical ability systematic approach problem analysis strong debugging troubleshooting skill good exposure retail domain willing relocate hyderbad present request part maintenance activity identify fix major defect application perform root cause analysis production issue subject matter expert involve multiple knowledge transfer knowledge sharing session client lead peer group take end end responsibility critical issue enhancement identify use case automate use now workflow automate various task involve manual intervention direct interaction client various business impact issue daily basis set meeting meeting client Project Objective provide end end maintenance support activity datum processing critical important web portal application use daily user large retailer world retail link portal host application develop technology supplier help carry daytoday activity right boarding tracking sale involve support various report help high management take business critical decision responsibility work major request part maintenance activity identify fix major defect application perform root cause analysis production issue subject matter expert involve multiple knowledge transfer knowledge sharing session client lead peer group take end end responsibility critical issue enhancement identify use case automate use now workflow automate various task involve manual intervention direct interaction client various business impact issue daily basis set meeting meeting client servicenow year year cobol year year Teradata year additional zos IDCAMS dfsort basic librarian CA7 basic qmf strength effective communication learn solve received award work various system improvement automation activity receive multiple insta award performance project work'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english', \n",
    "max_features= 1000, # keep top 1000 terms \n",
    "max_df = 0.5, \n",
    "smooth_idf=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264, 133)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_model = TruncatedSVD(n_components=10\n",
    "                         , algorithm='randomized', n_iter=100, random_state=122)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(n_components=10, n_iter=100, random_state=122)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(svd_model.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: \n",
      "use\n",
      " \n",
      "involve\n",
      " \n",
      "ability\n",
      " \n",
      "year\n",
      " \n",
      "various\n",
      " \n",
      "client\n",
      " \n",
      "analysis\n",
      " \n",
      "Topic 1: \n",
      "end\n",
      " \n",
      "involve\n",
      " \n",
      "use\n",
      " \n",
      "client\n",
      " \n",
      "ability\n",
      " \n",
      "analysis\n",
      " \n",
      "analytical\n",
      " \n",
      "Topic 2: \n",
      "various\n",
      " \n",
      "client\n",
      " \n",
      "issue\n",
      " \n",
      "analysis\n",
      " \n",
      "activity\n",
      " \n",
      "major\n",
      " \n",
      "manual\n",
      " \n",
      "Topic 3: \n",
      "year\n",
      " \n",
      "issue\n",
      " \n",
      "client\n",
      " \n",
      "activity\n",
      " \n",
      "automate\n",
      " \n",
      "involve\n",
      " \n",
      "critical\n",
      " \n",
      "Topic 4: \n",
      "client\n",
      " \n",
      "year\n",
      " \n",
      "activity\n",
      " \n",
      "application\n",
      " \n",
      "responsibility\n",
      " \n",
      "automate\n",
      " \n",
      "work\n",
      " \n",
      "Topic 5: \n",
      "year\n",
      " \n",
      "various\n",
      " \n",
      "automate\n",
      " \n",
      "activity\n",
      " \n",
      "analysis\n",
      " \n",
      "analytical\n",
      " \n",
      "daily\n",
      " \n",
      "Topic 6: \n",
      "application\n",
      " \n",
      "activity\n",
      " \n",
      "automate\n",
      " \n",
      "knowledge\n",
      " \n",
      "critical\n",
      " \n",
      "meeting\n",
      " \n",
      "issue\n",
      " \n",
      "Topic 7: \n",
      "automate\n",
      " \n",
      "activity\n",
      " \n",
      "knowledge\n",
      " \n",
      "meeting\n",
      " \n",
      "multiple\n",
      " \n",
      "work\n",
      " \n",
      "issue\n",
      " \n",
      "Topic 8: \n",
      "involve\n",
      " \n",
      "automate\n",
      " \n",
      "application\n",
      " \n",
      "activity\n",
      " \n",
      "critical\n",
      " \n",
      "various\n",
      " \n",
      "knowledge\n",
      " \n",
      "Topic 9: \n",
      "activity\n",
      " \n",
      "involve\n",
      " \n",
      "various\n",
      " \n",
      "analysis\n",
      " \n",
      "end\n",
      " \n",
      "datum\n",
      " \n",
      "critical\n",
      " \n"
     ]
    }
   ],
   "source": [
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "for i, comp in enumerate(svd_model.components_):\n",
    "    terms_comp = zip(terms, comp)\n",
    "    sorted_terms = sorted(terms_comp, key= lambda x:x[1], reverse=True)[:7]\n",
    "    print(\"Topic \"+str(i)+\": \")\n",
    "    for t in sorted_terms:\n",
    "        print(t[0])\n",
    "        print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'umap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-f50547fd9984>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mumap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_topics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvd_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUMAP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_dist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_topics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'umap'"
     ]
    }
   ],
   "source": [
    "import umap\n",
    "\n",
    "X_topics = svd_model.fit_transform(X)\n",
    "embedding = umap.UMAP(n_neighbors=150, min_dist=0.5, random_state=12).fit_transform(X_topics)\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], \n",
    "c = dataset.target,\n",
    "s = 10, # size\n",
    "edgecolor='none'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for testing app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import index\n",
    "from pandas._config.config import options\n",
    "import Cleaner\n",
    "import Similar\n",
    "import textract as tx\n",
    "import pandas as pd\n",
    "import os\n",
    "import tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_dir = \"Data/Resumes/\"\n",
    "job_desc_dir = \"Data/JobDesc/\"\n",
    "resume_names = os.listdir(resume_dir)\n",
    "job_description_names = os.listdir(job_desc_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_resumes(list_of_resumes, resume_directory):\n",
    "    placeholder = []\n",
    "    for res in list_of_resumes:\n",
    "        temp = []\n",
    "        temp.append(res)\n",
    "        text = tx.process(resume_directory+res, encoding='ascii')\n",
    "        text = str(text, 'utf-8')\n",
    "        temp.append(text)\n",
    "        placeholder.append(temp)\n",
    "    return placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = read_resumes(resume_names, resume_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cleaned_words(document):\n",
    "    for i in range(len(document)):\n",
    "        raw = Cleaner.Cleaner(document[i][1])\n",
    "        document[i].append(\" \".join(raw[0]))\n",
    "        document[i].append(\" \".join(raw[1]))\n",
    "        document[i].append(\" \".join(raw[2]))\n",
    "        sentence = tf_idf.do_tfidf(document[i][2].split(\" \"))\n",
    "        document[i].append(sentence)\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Doc=get_cleaned_words(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Database = pd.DataFrame(document,columns=[\"Name\",\"Context\",\"Cleaned\",\"Selective\",\"Selective_Reduced\",\"TF_Based\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Database.to_csv(\"Resume_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jobdescriptions(job_description_names, job_desc_dir):\n",
    "    placeholder = []\n",
    "    for tes in job_description_names:\n",
    "        temp = []\n",
    "        temp.append(tes)\n",
    "        text = tx.process(job_desc_dir+tes, encoding='ascii')\n",
    "        text = str(text, 'utf-8')\n",
    "        temp.append(text)\n",
    "        placeholder.append(temp)\n",
    "    return placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_document = read_jobdescriptions(job_description_names, job_desc_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jd=get_cleaned_words(job_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_database = pd.DataFrame(Jd,columns=[\"Name\",\"Context\",\"Cleaned\",\"Selective\",\"Selective_Reduced\",\"TF_Based\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_database.to_csv(\"Job_Data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'able advanced algorithm amount analysis analytics applied apply appropriate approval audio bachelors bayes begin build business candidate cassandra change client cnn common communication companys conduct conducting crunching cut d3js data databacke database datum decision define deliver deliverable design develop diagnostic discover distribution edge education enable energetic engineer even excellent experience experiment focus forests fulltime game gamechange generate ggplot good grasp great gurgaon haryana hbase help hide high hive identify implementation implementationfinetune improvement include independently information innovative insight integrate internal job keep knn language learn learning liaise limit look lstm machine make massage matlab meaningful mining ml model mongodb must naive nosql numerical numpy opencv operation opportunity performance pig plan prediction prefer preferred present primary product proficiency programming python quality query quickly record regression remote require resourceful responsibilities rnn salary science sciencemachine scientist script scripting selfstarter skill skills smart solutions specific sql statistic statistical strategy structured supervision svm system tactical team technique technology temporarily testing text tool toolkit type understanding unstructured use vast video vision visualisation warehousing weka well work year'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jd_database['TF_Based'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'accuracy achieve acquire active actively alankrit analysisdeep analysismachine analysissql analyst analystdata analytics area artificial aug augment authorization automated automation ba56b4f594cd449891db291ae8e04206last back bangaloredelhi bidirectional bilaspur binary brightness btech business capgemini category certification classification clean client cnn college commonly company compute computer computing context current cv data dataset datasets date datum day dce deep degree delhi dense designation details detecting detection develop duration education email embedding employment encode engineer engineering english epoch excel exist experience expert featured feeding field filter fire flatten follow foundation framework full functional glove google high hindi id image imagedatagenerator images incoming indiabengaluru industry initial integrated intelligence it join julsep jump kaggle kera keras key know kpo l2 lakh language languages last layer layers learn learning learningartificial learningdata library linux location look lstm machine manner marital mathematics mean ml model modeling models modified monitoring month months msexcel mttr name natural nature ncr networks neural nirjharpremium nlp notice number obtain occur offsite onsite other output padded percent perform period pg phone practitioner precision prediction pref preprocesse pretraine processing proficiency project projects python qualificationscertificationsprogram r2 read realtime recall record regex regression regularisation remote remove research resolution resume ridge role rotation rows sciencedata scientist score sectionwork self senior sentence sep sequence sequential server show singleunmarrie size skill skills smoke smokefire smokefiresafe speak sql stack statistical status stopword subcategory summary switch team technical tensorflow term test text ticket time title tokenize tool tools top total train trained training transfer ug unsafe use verified version vision visualizationsqlpythonmsexcelstatistical windows word word2vec work workfromhome write year years zoom'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Database['TF_Based'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Email and Other Relevant information from text\n",
    "\n",
    "- Email\n",
    "- Phone number\n",
    "- School"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Spacy's PhraseMatcher and Custom Rules and libraries. (Note this is a Fuzzy Matching Technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher, PhraseMatcher\n",
    "import pandas as pd\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('../Dataset/Resume_1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = df['Person 6'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = [{}, {'Lower':'college'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nlp(\"AVG College of Engineering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('Pf', None, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matcher(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8356421937038671505, 0, 2)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in doc:\n",
    "    if text.like_email == True:\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for text in doc.ents:\n",
    "#     if text.label == ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "file = resume\n",
    "\n",
    "for line in file:\n",
    "    urls = re.findall('https?://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+', line)\n",
    "print(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urlextract import URLExtract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['indeed.com/r/Anvitha-Rao/9d6acc68cc30c71c', 'https://www.indeed.com/r/Anvitha-Rao/9d6acc68cc30c71c?isid=rex-download&ikw=download-top&co=IN', 'http://www.ijrcct.org/index.php/ojs/article/view/1416', 'https://www.linkedin.com/in/anvitha-d-rao-65a068a7', 'https://www.linkedin.com/in/anvitha-d-rao-65a068a7']\n",
      "hackerrank.com//srbhr\n",
      "Given text contains some URL \n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from urlextract import URLExtract\n",
    "\n",
    "extractor = URLExtract()\n",
    "urls = extractor.find_urls(resume)\n",
    "print(urls) # prints: ['example.com']\n",
    "\n",
    "# Another way is to get a generator over found URLs in text:\n",
    "for url in extractor.gen_urls( \"hackerrank.com//srbhr\"):\n",
    "    print(url) # prints: ['example.com']\n",
    "\n",
    "# Or if you want to just check if there is at least one URL in text:\n",
    "if extractor.has_urls(resume):\n",
    "    print(\"Given text contains some URL \\nTrue\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Institute = [{'TEXT': {\"REGEX\": \"^[Ii](\\.?|nstitute)$\"}}]\n",
    "College = [{'TEXT': {\"REGEX\": \"^[Cc](\\.?|ollege)$\"}}]\n",
    "University = [{'TEXT': {\"REGEX\": \"^[Uu](\\.?|niversity)$\"}}]\n",
    "Technology = [{'TEXT': {\"REGEX\": \"^[Tt](\\.?|echnology)$\"}}]\n",
    "Management = [{'TEXT': {\"REGEX\": \"^[Mm](\\.?|anagement)$\"}}]\n",
    "Engineering = [{'TEXT': {\"REGEX\": \"^[Ee](\\.?|ngineering)$\"}}]\n",
    "Commerce = [{'TEXT': {\"REGEX\": \"^[Ii](\\.?|nstitute)$\"}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "schpattern = [{}, {}, {\"TEXT\": {\"REGEX\": \"^[Ss](\\.?|chool)$\"}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('ID_SCH', None, schpattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6957050711476831226, 411, 414)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S Ramaiah"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[413:415]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anvitha Rao\n",
      "Automation developer\n",
      "\n",
      "- Email me on Indeed: indeed.com/r/Anvitha-Rao/9d6acc68cc30c71c\n",
      "\n",
      "Seeking a software development internship position for Summer 2018 that utilizes my technical\n",
      "skills, education and passion for\n",
      "solving interesting problems as a software professional.\n",
      "\n",
      "Willing to relocate: Anywhere\n",
      "\n",
      "WORK EXPERIENCE\n",
      "\n",
      "Automation developer\n",
      "\n",
      "SAP Labs -  Bengaluru, Karnataka -\n",
      "\n",
      "August 2016 to August 2017\n",
      "\n",
      "Worked as an automation developer in the development of cloud based Human capital\n",
      "management System and\n",
      "Integration frameworks Dell Boomi and SAP HANA Cloud Platform Integration.\n",
      "● Development of automation framework using Java Selenium and RestFul API's for payroll\n",
      "projects.\n",
      "● Collaborating with customers on migrating Payroll projects to SAP HANA Cloud Platform\n",
      "Integration.\n",
      "● Involved in regression, unity, functionality, performance, sanity and acceptance test driven\n",
      "development process.\n",
      "\n",
      "Intern\n",
      "\n",
      "SAP Labs -  Bengaluru, Karnataka -\n",
      "\n",
      "February 2016 to July 2016\n",
      "\n",
      "Worked on migrating Business intelligence tool, Universe Design Tool in Visual Studio using C++.\n",
      "● Automation of test cases for identifying operations supported by databases using Java.\n",
      "● Tools: Universe Design Tool, Information Design Tool, Webi and Perforce.\n",
      "\n",
      "Projects:\n",
      "GeoSpark Integrated with Apache Hadoop\n",
      "● Identifies top 50 pick up points in New York city based on distributed New York taxi data using\n",
      "Apache Spark and Scala.\n",
      "Iaas Implementation: Cloud application for Image Recognition\n",
      "● This project uses Amazon S3, SQS and EC2 instances to provide Image recognition service to\n",
      "users by implementing load\n",
      "balancing and web services.\n",
      "Spam Detection\n",
      "● Identifying spam messages using Natural Language processing techniques in python.\n",
      "Analysis of Financial Data\n",
      "\n",
      "https://www.indeed.com/r/Anvitha-Rao/9d6acc68cc30c71c?isid=rex-download&ikw=download-top&co=IN\n",
      "\n",
      "\n",
      "● Exploratory data analysis of stock prices using various data visualization techniques in pandas\n",
      "and d3.js\n",
      "Effective prediction and prevention of air pollution caused due to automobiles using IoT and data\n",
      "analytics techniques\n",
      "● Analyzes pollutants at different geographical locations and suggests a least polluted route on\n",
      "an android application.\n",
      "● Co-authored a paper --Ref link: http://www.ijrcct.org/index.php/ojs/article/view/1416\n",
      "\n",
      "EDUCATION\n",
      "\n",
      "Masters in Computer Science\n",
      "\n",
      "Arizona State University -  Tempe, AZ\n",
      "\n",
      "September 2019\n",
      "\n",
      "Bachelor of Engineering in Computer Science\n",
      "\n",
      "M S Ramaiah Institute of Technology -  Bengaluru, Karnataka\n",
      "\n",
      "September 2012 to June 2016\n",
      "\n",
      "SKILLS\n",
      "\n",
      "JAVA (1 year), C++ (Less than 1 year), Hadoop (Less than 1 year), HADOOP (Less than 1 year),\n",
      "CSS (Less than 1 year)\n",
      "\n",
      "LINKS\n",
      "\n",
      "https://www.linkedin.com/in/anvitha-d-rao-65a068a7\n",
      "\n",
      "ADDITIONAL INFORMATION\n",
      "\n",
      "Technical Skills:\n",
      "Programming Languages: C, C++, HTML/CSS, Java, Python, Javascript\n",
      "\n",
      "Technologies: IoT, MySQL, PostgreSQL, D3js, Hadoop and Spark, Gephi\n",
      "\n",
      "https://www.linkedin.com/in/anvitha-d-rao-65a068a7\n"
     ]
    }
   ],
   "source": [
    "print(resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
